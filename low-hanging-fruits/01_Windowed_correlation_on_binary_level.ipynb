{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyse the windowed correlations over the different files at binary level.\n",
    "\n",
    "> Add complementary content from the past\n",
    "> - The analysis which showed that the residual is not equally distributed like `white note`\n",
    "> - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import plot_slice\n",
    "# def plot_slice(df, s):\n",
    "#     fig, ax = plt.subplots(2, figsize=(9,10), sharex=True)\n",
    "#     df.iloc[:,s].plot(legend=False, ax=ax[0]);\n",
    "#     elements = np.arange(df.index.size)+1\n",
    "#     df.iloc[:,s].multiply(df.index.size).divide(elements, axis=0).plot(legend=False, ax=ax[1])\n",
    "#     # plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#     ax[0].set_title(\"Elements {}\".format(s))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.csv\"\n",
    "df = pd.read_csv(source, skiprows=1, index_col=0).astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.corr() > .9).sum().sum() == df.columns.size  # since the threshold was set to .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), 27, 27, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((27, 27), 14, 14, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((41, 41), 11, 11, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((52, 52), 7, 7, fill=False, edgecolor='blue', lw=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can algorithms see this pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,27,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(27,42,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(42,52,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(52,None,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoLZC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.nlzc.32.95.csv\"\n",
    "df = pd.read_csv(source, skiprows=1, index_col=0).astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), 41, 41, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((41, 41), 9, 9, fill=False, edgecolor='blue', lw=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,41,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(41,None,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.bplanes.32.csv\"\n",
    "df = pd.read_csv(source, skiprows=1, index_col=0).astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), 5, 5, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((5, 5), 4, 4, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((9, 9), 4, 4, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((13, 13), 20, 20, fill=False, edgecolor='blue', lw=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,6,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(6,9,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(9,13,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(13,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic discovery of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method, metric = \"average\", \"euclidean\"\n",
    "link = scipy.cluster.hierarchy.linkage(df.corr(), method=method, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import get_members_of_lvl\n",
    "# def get_members_of_lvl(lvl, link):\n",
    "#     LVL = namedtuple(\"Level\",\"members,lvl\")\n",
    "#     clusters = [LVL(members=[x], lvl=0) for x in range(link.shape[0]+1)]\n",
    "#     for i in range(link.shape[0]):\n",
    "#         ix_1,ix_2 = int(link[i][0]), int(link[i][1])\n",
    "#         group = clusters[ix_1].members + clusters[ix_2].members\n",
    "#         max_group_number = max(clusters[ix_1].lvl,clusters[ix_2].lvl)\n",
    "#         clusters[ix_1] = LVL(members=clusters[ix_1].members, lvl=max_group_number)\n",
    "#         clusters[ix_2] = LVL(members=clusters[ix_2].members, lvl=max_group_number)\n",
    "#         new_lvl = max_group_number + 1\n",
    "#         clusters.append(LVL(members=sorted(group), lvl=new_lvl))\n",
    "#     maximum_lvl = clusters[-1].lvl\n",
    "#     clusters = [LVL(x.members,maximum_lvl-x.lvl) for x in clusters]\n",
    "    \n",
    "#     selection = [x for x in clusters if x.lvl==lvl]\n",
    "#     lvl -= 1\n",
    "#     while lvl > 0:\n",
    "#         candidates = [x for x in clusters if x.lvl==lvl]\n",
    "#         winner = [x for x in candidates if not set(selection[0].members).issubset(set(x.members))]\n",
    "#         selection.append(winner[0])\n",
    "#         lvl -= 1\n",
    "#     return [s.members for s in selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_members_of_lvl(3, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15), method=method, metric=metric);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can algorithmically define/discover clusters of probabability distributions. After this we need to merge these probability distributions to single representations and with this define a probability tablel including the representations and specific group members. \n",
    "\n",
    "The clustering methods used are described on the [scipy page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html). There are similarities with the Hufmann algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Bi/Co-Clustering\n",
    "Information about the spectral bi and co clustering methods can be found [here](https://scikit-learn.org/stable/modules/biclustering.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster.bicluster import SpectralCoclustering, SpectralBiclustering\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import get_spectral_clusters\n",
    "# def get_spectral_clusters(corrarr, n_clusters=5, mode='co'):\n",
    "#     if mode=='co':\n",
    "#         model = SpectralCoclustering(n_clusters, random_state=0)\n",
    "#         model.fit(corrarr)\n",
    "#         indices = np.arange(df.columns.size)\n",
    "#         clusters = [indices[x].tolist() for x in model.columns_]\n",
    "#         return clusters\n",
    "#     elif mode=='bi':\n",
    "#         model = SpectralBiclustering(n_clusters, random_state=0)\n",
    "#         model.fit(corrarr)\n",
    "#         indices = np.arange(df.columns.size)\n",
    "#         clusters = [indices[x].tolist() for x in model.columns_]\n",
    "#         return clusters\n",
    "        \n",
    "#     else:\n",
    "#         raise(\"Mode wrong?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_spectral_clusters(df.corr(), mode='co')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_spectral_clusters(df.corr(), mode='bi')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import plot_clustered_heatmap\n",
    "# def plot_clustered_heatmap(df, clusters):\n",
    "#     fig, ax = plt.subplots(figsize=(15,15))\n",
    "#     rearranged = df.iloc[:,[x for x in chain.from_iterable(clusters)]]\n",
    "#     sns.heatmap(rearranged.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "#     i = 0\n",
    "#     start = 0\n",
    "#     while i < len(clusters):\n",
    "#         ax.add_patch(Rectangle((start, start), len(clusters[i]), \n",
    "#                                len(clusters[i]), fill=False, edgecolor='blue', lw=3));\n",
    "#         start += len(clusters[i])\n",
    "#         i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustered_heatmap(df, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    plot_slice(df, cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spectral bi clustering algorithm could be helpful in identifying groups of subprediction tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of all algorithmic selection of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import building_clusters\n",
    "# def building_clusters(corrarr, mode, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Clustering of different probability strains to identify merging possibilities.\n",
    "    \n",
    "#     Clustering algorithms tree:\n",
    "    \n",
    "#             bi :\n",
    "#           /      Both algorithm use spectral clustering defined in sklearn. Need: < n_clusters >\n",
    "#     start - co :\n",
    "#           \\ \n",
    "#             easy : Uses algorithms implemented in scipy: Need: < method >, < metric >, < lvl >\n",
    "            \n",
    "#     \"\"\"\n",
    "#     assert mode in [\"bi\",\"co\",\"easy\"], \"Unknown mode\"\n",
    "#     if mode == \"easy\":\n",
    "#         necessary = ['method', 'metric', 'lvl']\n",
    "#         missing = [x for x in necessary if x not in kwargs.keys()]\n",
    "#         assert not missing, \"Missing keywords {}\".format(missing)\n",
    "#         method, metric, lvl = kwargs['method'], kwargs['metric'], kwargs['lvl']\n",
    "#         link = scipy.cluster.hierarchy.linkage(corrarr, method=method, metric=metric)\n",
    "#         return get_members_of_lvl(link=link, lvl=lvl)\n",
    "#     else:\n",
    "#         necessary = ['n_clusters']\n",
    "#         missing = [x for x in necessary if x not in kwargs.keys()]\n",
    "#         assert not missing, \"Missing keywords {}\".format(missing)\n",
    "#         n_clusters = kwargs['n_clusters']\n",
    "#         return get_spectral_clusters(corrarr, mode=mode, n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_clusters(df.corr(), 'bi', n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustered_heatmap(df, clusters=clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in clusters:\n",
    "    plot_slice(df, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of backward/forward probabilities of original MQ encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward = pd.read_pickle('mq_backwards_probabilities.pickle').fillna(np.nan)\n",
    "forward   = pd.read_pickle('mq_forward_probabilities.pickle').fillna(np.nan).iloc[:,:-1]\n",
    "probs = 'backward'; df = backward if probs == 'backward' else forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.75});\n",
    "ax.set_title(\"Original {} probabilities MQ\".format(probs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = building_clusters(df.corr(), 'co', n_clusters=3)[0]\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustered_heatmap(df, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from clustering import get_multi_index_df\n",
    "sns.lineplot(data = get_multi_index_df(df, clusters));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = get_multi_index_df(df, clusters));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['orange','red','green','skyblue']\n",
    "for i,c in enumerate(clusters):\n",
    "    for v in c:\n",
    "        df.iloc[:,v].plot(color=colors[i], style=':', marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in clusters:\n",
    "    plot_slice(df, c, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = 'forward'; df = backward if probs == 'backward' else forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.75});\n",
    "ax.set_title(\"Original {} probabilities MQ\".format(probs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import map_correlation_back_to_original\n",
    "# orig_index = []\n",
    "# for cluster in mclusters[0]:\n",
    "#     orig_index.append([list(df.columns.values).index(mclusters[1][x]) for x in cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = building_clusters(df.corr(), 'co', n_clusters=3)[0]\n",
    "mclusters = building_clusters(cross_correlation(df, 15), 'co', n_clusters=3)\n",
    "mclusters = map_correlation_back_to_original(df, mclusters)\n",
    "print(clusters)\n",
    "print(mclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustered_heatmap(df, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cs in clusters[:3]:\n",
    "    plot_slice(df, cs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustered_heatmap(df, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cdf = get_multi_index_df(df, clusters)\n",
    "sns.lineplot(data=cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider nan values in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correlation(df, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = building_clusters(df.corr(), 'co', n_clusters=3)\n",
    "mclusters = building_clusters(cross_correlation(df,9), 'co', n_clusters=3)\n",
    "orig_index = map_correlation_back_to_original(df, mclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*clusters, sep='\\n')\n",
    "print('')\n",
    "print(*mclusters, sep='\\n')\n",
    "print('')\n",
    "print(*[orig_index], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation method needs to calculate the minimal number of values in the correlation to be successfull. If this is not met than the correlation is kicked out. To prevent recoding we calculate cross correlation using a wrapper function to kick out these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import get_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters(df, 'co', n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters(df, minimum=9,mode='co', n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_multi_index_df(df, get_clusters(df, minimum=19,mode='co', n_clusters=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters(df, minimum=19,mode='co', n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_clusters(df,mode='co', n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import plot_sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sns(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
