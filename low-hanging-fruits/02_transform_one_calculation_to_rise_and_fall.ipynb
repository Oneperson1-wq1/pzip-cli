{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustering as cs\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename, ext = 'mq_forward_probabilities.pickle', True\n",
    "df = pd.read_pickle(filename).fillna(np.nan)\n",
    "clusters = cs.calculate_clusters(df, mode='co', minimum=1, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs.plot_clustered_heatmap(df, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs.plot_sns(df, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename, ext = 'mq_backwards_probabilities.pickle', True\n",
    "df = pd.read_pickle(filename).fillna(np.nan)\n",
    "clusters = cs.calculate_clusters(df, mode='co', minimum=1, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs.plot_clustered_heatmap(df, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs.plot_sns(df, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename, ext = '../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.bplanes.32.csv', True\n",
    "df = pd.read_csv(filename, skiprows=1, index_col=0).astype(float)\n",
    "ones = df.multiply(df.index.size).divide(np.arange(df.index.size)+1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = ones > .5\n",
    "groups = criteria\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupclusters = (groups.shift(1) != groups).astype(int).cumsum()\n",
    "groupclusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "for col in groupclusters:\n",
    "    groupclusters[col+'b'] = groupclusters[col]\n",
    "    groupclusters.drop(col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_with_blocks = pd.concat([criteria, groupclusters], axis=1)\n",
    "ones_with_blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_columns = 0\n",
    "for col in ones:\n",
    "    dframe = ones_with_blocks.reset_index().groupby([col,col+'b'])['ix'].apply(np.array)\n",
    "    total_columns += dframe.size\n",
    "total_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blocks = np.ones((ones.index.size,total_columns))*np.nan\n",
    "blocks = pd.DataFrame(blocks, columns=[\"c{:03d}\".format(x) for x in range(total_columns)])\n",
    "blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blocks(ones):\n",
    "    criteria = ones > .5\n",
    "    groups = criteria\n",
    "    groupclusters = (groups.shift(1) != groups).astype(int).cumsum()\n",
    "    \n",
    "    # Rename columns\n",
    "    for col in groupclusters:\n",
    "        groupclusters[col+'b'] = groupclusters[col]\n",
    "        groupclusters.drop(col, inplace=True, axis=1)\n",
    "    ones_with_blocks = pd.concat([criteria, groupclusters], axis=1)\n",
    "    \n",
    "    # Calculate columns\n",
    "    total_columns = 0\n",
    "    for col in ones:\n",
    "        dframe = ones_with_blocks.reset_index().groupby([col,col+'b'])['ix'].apply(np.array)\n",
    "        total_columns += dframe.size\n",
    "    total_columns\n",
    "    \n",
    "    # Create blocks\n",
    "    blocks = np.ones((ones.index.size,total_columns))*np.nan\n",
    "    blocks = pd.DataFrame(blocks, columns=[\"c{:03d}\".format(x) for x in range(total_columns)])\n",
    "    \n",
    "    ix = 0\n",
    "    get_rid = []\n",
    "    for col in ones:\n",
    "        dframe = ones_with_blocks.reset_index().groupby([col,col+'b'])['ix'].apply(np.array)\n",
    "        for indices in dframe:\n",
    "            s = [x for x in range(indices.size)]\n",
    "            blocks[\"c{:03d}\".format(ix)][s] = ones[col][indices].values\n",
    "            ix+=1\n",
    "    \n",
    "    for col in blocks:\n",
    "        i = 0\n",
    "        while i < blocks.index.size:\n",
    "            shifted = blocks.loc[:,col].shift(-i)\n",
    "            if shifted[0] < 1 and shifted[0] > 0:\n",
    "                blocks.loc[:,col] = blocks.loc[:,col].shift(-i)\n",
    "                break\n",
    "            i+=1\n",
    "        if i == 32:\n",
    "            blocks.drop(col, inplace=True, axis=1)\n",
    "    \n",
    "    for col in blocks:\n",
    "        if (blocks[col][:2] > .5).all():\n",
    "            blocks[col] = 1 - blocks[col]\n",
    "        elif blocks[col][0] > .5 and np.isnan(blocks[col][1]):\n",
    "            blocks[col] = 1 - blocks[col]\n",
    "    \n",
    "    assert (blocks.iloc[0,:] > .5).sum() == 0, \"Woooohooooo///\"\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 0\n",
    "get_rid = []\n",
    "for col in ones:\n",
    "    dframe = ones_with_blocks.reset_index().groupby([col,col+'b'])['ix'].apply(np.array)\n",
    "    for indices in dframe:\n",
    "        s = [x for x in range(indices.size)]\n",
    "        blocks[\"c{:03d}\".format(ix)][s] = ones[col][indices].values\n",
    "        ix+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_entries = blocks.loc[:,blocks.index.size - blocks.isna().sum() > 10]\n",
    "# valid_entries.loc[:, valid_entries.corr().isna().sum() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_with_at_least_k_valid_values(df, k):\n",
    "    return df.loc[:,df.index.size - df.isna().sum() > k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_series_with_at_least_k_valid_values(blocks, 10).diff().cumsum()\n",
    "# blocks[blocks.diff().cumsum() == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in blocks:\n",
    "    i = 0\n",
    "    while i < blocks.index.size:\n",
    "        shifted = blocks.loc[:,col].shift(-i)\n",
    "        if shifted[0] < 1 and shifted[0] > 0:\n",
    "            blocks.loc[:,col] = blocks.loc[:,col].shift(-i)\n",
    "            break\n",
    "        i+=1\n",
    "    if i == 32:\n",
    "        blocks.drop(col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in blocks:\n",
    "    if (blocks[col][:2] > .5).all():\n",
    "        blocks[col] = 1 - blocks[col]\n",
    "    elif blocks[col][0] > .5 and np.isnan(blocks[col][1]):\n",
    "        blocks[col] = 1 - blocks[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(blocks.iloc[0,:] > .5).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_equal(a,b):\n",
    "    try:\n",
    "        np.testing.assert_equal(a,b)\n",
    "    except AssertionError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_equal(blocks.values, create_blocks(ones).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_columns(blocks, sinks, col, sink):\n",
    "    result = dict()\n",
    "    sink = 1\n",
    "    for (bit, df) in sinks[col].reset_index().groupby(col):\n",
    "        indices = df['index'].index.values\n",
    "        if bit == sink:\n",
    "            result['sinking'] = split_and_fill(blocks[col], indices)\n",
    "        else:\n",
    "            result['rising'] = split_and_fill(blocks[col], indices)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_continues_behaviour(indices):\n",
    "    splits = []\n",
    "    subset = [indices[0]-1, indices[0]] if indices[0] != 0 else [indices[0]]\n",
    "    for v in indices[1:]:\n",
    "        if np.isnan(v):\n",
    "            break\n",
    "        if v == subset[-1]+1:\n",
    "            subset.append(v)\n",
    "        else:\n",
    "            splits.append(subset)\n",
    "            subset = [v-1, v]\n",
    "    splits.append(subset)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nans(series, splits):\n",
    "    goal = series.size\n",
    "    result = []\n",
    "    for s in splits:\n",
    "        data = np.ones(goal) * np.nan\n",
    "        data[np.arange(len(s))] = series[s]\n",
    "        result.append(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_fill(series, indices):\n",
    "    splits = split_by_continues_behaviour(indices)\n",
    "#     print(series,splits)\n",
    "    result = add_nans(series, splits)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_sinking_df(df):\n",
    "    sinking = (blocks.shift(1) >= blocks).astype(int)  # 1 if it is sinking\n",
    "    sinking.iloc[0,:] = sinking.iloc[1,:]\n",
    "    return sinking, 1\n",
    "\n",
    "sinking = create_sinking_df(blocks)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from functools import namedtuple\n",
    "\n",
    "def final_function(ones):\n",
    "    df = create_blocks(ones)\n",
    "    sinking, sink = create_sinking_df(df)\n",
    "    r_f_splits = [split_columns(blocks, sinking, col, sink) for col in sinking]\n",
    "    sinking = [x['sinking'] for x in r_f_splits if 'sinking' in x.keys()]\n",
    "    sinking = pd.DataFrame(list(chain.from_iterable(sinking)))\n",
    "    sinking.name = 'sinking'\n",
    "    \n",
    "    rising = [x['rising'] for x in r_f_splits if 'rising' in x.keys()]\n",
    "    rising = pd.DataFrame(list(chain.from_iterable(rising)))\n",
    "    rising.name = 'rising'\n",
    "    \n",
    "    result = namedtuple('result', 'rising, sinking')\n",
    "    return result(rising.T, sinking.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_function(ones).sinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
