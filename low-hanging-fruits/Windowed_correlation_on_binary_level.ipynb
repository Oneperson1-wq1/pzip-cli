{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyse the windowed correlations over the different files at binary level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slice(df, s):\n",
    "    fig, ax = plt.subplots(2, figsize=(9,10), sharex=True)\n",
    "    df.iloc[:,s].plot(legend=False, ax=ax[0]);\n",
    "    elements = np.arange(df.index.size)+1\n",
    "    df.iloc[:,s].multiply(df.index.size).divide(elements, axis=0).plot(legend=False, ax=ax[1])\n",
    "    # plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.csv\"\n",
    "df = pd.read_csv(source, skiprows=1, index_col=0).astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.corr() > .9).sum().sum() == df.columns.size  # since the threshold was set to .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), 27, 27, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((27, 27), 14, 14, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((41, 41), 11, 11, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((52, 52), 7, 7, fill=False, edgecolor='blue', lw=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can algorithms see this pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,27,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(27,42,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(42,52,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(52,None,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoLZC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.nlzc.32.95.csv\"\n",
    "df = pd.read_csv(source, skiprows=1, index_col=0).astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), 41, 41, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((41, 41), 9, 9, fill=False, edgecolor='blue', lw=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,41,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(41,None,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../emac.ml.tm1.f32.little.5x90x160x320_3.raw.residual.bplanes.32.csv\"\n",
    "df = pd.read_csv(source, skiprows=1, index_col=0).astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), ax=ax, square=True, cbar_kws={\"shrink\": 0.5});\n",
    "\n",
    "ax.add_patch(Rectangle((0, 0), 5, 5, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((5, 5), 4, 4, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((9, 9), 4, 4, fill=False, edgecolor='blue', lw=3));\n",
    "ax.add_patch(Rectangle((13, 13), 20, 20, fill=False, edgecolor='blue', lw=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(None,6,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(6,9,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(9,13,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(df, slice(13,None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method, metric = \"average\", \"euclidean\"\n",
    "link = scipy.cluster.hierarchy.linkage(df.corr(), method=method, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_members_of_lvl(lvl, link):\n",
    "    LVL = namedtuple(\"Level\",\"members,lvl\")\n",
    "    clusters = [LVL(members=[x], lvl=0) for x in range(link.shape[0]+1)]\n",
    "    for i in range(link.shape[0]):\n",
    "        ix_1,ix_2 = int(link[i][0]), int(link[i][1])\n",
    "        group = clusters[ix_1].members + clusters[ix_2].members\n",
    "        max_group_number = max(clusters[ix_1].lvl,clusters[ix_2].lvl)\n",
    "        clusters[ix_1] = LVL(members=clusters[ix_1].members, lvl=max_group_number)\n",
    "        clusters[ix_2] = LVL(members=clusters[ix_2].members, lvl=max_group_number)\n",
    "        new_lvl = max_group_number + 1\n",
    "        clusters.append(LVL(members=sorted(group), lvl=new_lvl))\n",
    "    maximum_lvl = clusters[-1].lvl\n",
    "    clusters = [LVL(x.members,maximum_lvl-x.lvl) for x in clusters]\n",
    "    \n",
    "    selection = [x for x in clusters if x.lvl==lvl]\n",
    "    lvl -= 1\n",
    "    while lvl > 0:\n",
    "        candidates = [x for x in clusters if x.lvl==lvl]\n",
    "        winner = [x for x in candidates if not set(selection[0].members).issubset(set(x.members))]\n",
    "        selection.append(winner[0])\n",
    "        lvl -= 1\n",
    "    for s in selection:\n",
    "        print(s.members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_members_of_lvl(3, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), figsize=(15,15), method=\"average\", metric=\"euclidean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can algorithmically define/discover clusters of probabability distributions. After this we need to merge these probability distributions to single representations and with this define a probability tablel including the representations and specific group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
